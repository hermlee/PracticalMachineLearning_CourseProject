# Course Project of Practical Machine Learning
#### _**Xin Li**_
#### _**October 7, 2016**_ 
## Background Information 
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement and a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.
## Libraries
In this project, we applied _**caret**_, _**e1071**_, and _**rattle**_ libraries.
```
library(caret)
library(rattle)
library(e1071)
```
## Data Processing
### Import the Data
When importing the data, "NA", "#DIV/0!", and "" are recognized as missing values.
```
trData <- read.csv(paste(directory,'/pml-training.csv',sep=''),na.strings=c("NA","#DIV/0!",""))
tsData <- read.csv(paste(directory,'/pml-testing.csv',sep=''),na.strings=c("NA","#DIV/0!",""))
```
### Data Cleaning
We first delect the columns with too many missing values. Here we set the threshold to be 80%. In other words, if a column contains more than 80% of missing values, this column is deleted.
```
N_row <- nrow(trData)
N_col <- ncol(trData)
threshold <- 0.8
col_na <- NULL
for (i in 1:N_col) {
	if (sum(is.na(trData[,i]))>(N_row*threshold)){
		col_na <- append(col_na,i)
	}
}
if (length(col_na)>0) {
	trData <- trData[,-col_na]
	tsData <- tsData[,-col_na]
}
```
After the column deletion, the number of columns is reduced from 159 to 59. Also we need to remove the first column. 
```
trData <- trData[,c(-1)]
tsData <- tsData[,c(-1)]
```
Now, delete the rows with missing data from the training data:
```
row_na <- NULL
for (i in N_row) {
	if (sum(is.na(trData[i,]))>0){
		row_na <- append(row_na,i)
	}
}
if (length(row_na>0)) {
	trData <- trData[-row_na,]
}
```
### Data Partition
```
set.seed(1989)
intrain <- createDataPartition (trData$classe,p=0.7,list=FALSE)
data_train <- trData[intrain,]
data_test <- trData[-intrain,]
```
### Cross Validation
In this project we applied the 5-fold cross validation.
```
ctrl <- trainControl(method='cv',num = 5)
```
## Prediction Models
In this project we apply three different methods to do the predition. They are: classification tree, random forest, and support vector machine (SVM). 
### Classification Tree
```
mod_rpart <- train(classe ~ ., data=data_train, method="rpart", trControl=ctrl)
```
The results are as follows:
```
## CART 
##
## 13737 samples
##    58 predictor
##     5 classes: 'A', 'B', 'C', 'D', 'E' 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 10990, 10988, 10989, 10991, 10990 
## Resampling results across tuning parameters:
## 
##   cp          Accuracy   Kappa     
##   0.03529651  0.6264026  0.52894558
##   0.03617808  0.5068104  0.34807944
##   0.11341674  0.3310836  0.07136299

## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was cp = 0.03529651. 
```
The tree
```
fancyRpartPlot(mod_rpart$finalModel)
```
![The tree generated by 'rpart'](/rpart.jpeg)
Evaluation
```
pred_rpart <- predict(mod_rpart,data_test)
conf_rpart <- confusionMatrix(data_test$classe,pred_rpart)
```
```
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1257  140  184   90    3
##          B  289  462  203  185    0
##          C   39  109  855   23    0
##          D   41  165  276  482    0
##          E   13  269  242   53  505
## 
## Overall Statistics
##                                           
##                Accuracy : 0.6051          
##                  95% CI : (0.5925, 0.6176)
##     No Information Rate : 0.2991          
##     P-Value [Acc > NIR] : < 2.2e-16       
##                                           
##                   Kappa : 0.5013          
##  Mcnemar's Test P-Value : < 2.2e-16       
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.7669   0.4035   0.4858   0.5786  0.99409
## Specificity            0.9018   0.8572   0.9585   0.9046  0.89269
## Pos Pred Value         0.7509   0.4056   0.8333   0.5000  0.46673
## Neg Pred Value         0.9093   0.8561   0.8137   0.9287  0.99938
## Prevalence             0.2785   0.1946   0.2991   0.1415  0.08632
## Detection Rate         0.2136   0.0785   0.1453   0.0819  0.08581
## Detection Prevalence   0.2845   0.1935   0.1743   0.1638  0.18386
## Balanced Accuracy      0.8344   0.6303   0.7222   0.7416  0.94339
```
from the confusion matrix, the accuracy is 0.6051, which is not good enough.
### Random Forest
Now we apply random forest.
```
set.seed(2017)
mod_rf <- train(classe~., data=data_train, method='rf',trControl=ctrl)
```
Use confusion matrix to evalute the model
```
pred_rf <- predict(mod_rf,data_test)
conf_rf <- confusionMatrix(data_test$classe,pred_rpart)
```
The results are:
```
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1674    0    0    0    0
##          B    1 1138    0    0    0
##          C    0    0 1025    1    0
##          D    0    0    2  959    3
##          E    0    0    0    0 1082
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9988          
##                  95% CI : (0.9976, 0.9995)
##     No Information Rate : 0.2846          
##     P-Value [Acc > NIR] : < 2.2e-16       
##                                           
##                   Kappa : 0.9985          
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9994   1.0000   0.9981   0.9990   ## 0.9972
## Specificity            1.0000   0.9998   0.9998   0.9990   1.0000
## Pos Pred Value         1.0000   0.9991   0.9990   0.9948   1.0000
## Neg Pred Value         0.9998   1.0000   0.9996   0.9998   0.9994
## Prevalence             0.2846   0.1934   0.1745   0.1631   0.1844
## Detection Rate         0.2845   0.1934   0.1742   0.1630   0.1839
## Detection Prevalence   0.2845   0.1935   0.1743   0.1638   0.1839
## Balanced Accuracy      0.9997   0.9999   0.9989   0.9990   0.9986
```
### SVM
Now apply SVM
```
set.seed(15452)
mod_svm <- svm(classe~., data=data_train, trControl=ctrl)
```
Use confusion matrix to evalute the model
```
pred_svm <- predict(mod_svm,data_test)
conf_svm <- confusionMatrix(data_test$classe,pred_svm)
```
And the result is
```
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1665    2    7    0    0
##          B  114  998   26    0    1
##          C    0   47  967   12    0
##          D    0    0   73  888    3
##          E    0    0    4   27 1051
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9463          
##                  95% CI : (0.9402, 0.9519)
##     No Information Rate : 0.3023          
##     P-Value [Acc > NIR] : < 2.2e-16       
##                                           
##                   Kappa : 0.9319          
## Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9359   0.9532   0.8979   0.9579   0.9962
## Specificity            0.9978   0.9709   0.9877   0.9847   0.9936
## Pos Pred Value         0.9946   0.8762   0.9425   0.9212   0.9713
## Neg Pred Value         0.9729   0.9897   0.9774   0.9921   0.9992
## Prevalence             0.3023   0.1779   0.1830   0.1575   0.1793
## Detection Rate         0.2829   0.1696   0.1643   0.1509   0.1786
## Detection Prevalence   0.2845   0.1935   0.1743   0.1638   0.1839
## Balanced Accuracy      0.9669   0.9620   0.9428   0.9713   0.9949
```
The accuracy is 0.9463.
## Prediction 
Among the three algorithms applied, random forest has the highest accuracy. Therefore, we use random forest to do the prediction.
```
pred_test <- predict(mod_rf,tsData)
```

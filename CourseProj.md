# Course Project of Practical Machine Learning
#### _**Xin Li**_
#### _**October 7, 2016**_ 
## Background Information 
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement and a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways.
## Libraries
In this project, we applied _**caret**_, _**e1071**_, and _**rattle**_ libraries.
```
library(caret)
library(rattle)
library(e1071)
```
## Data Processing
### Import the Data
When importing the data, "NA", "#DIV/0!", and "" are recognized as missing values.
```
trData <- read.csv(paste(directory,'/pml-training.csv',sep=''),na.strings=c("NA","#DIV/0!",""))
tsData <- read.csv(paste(directory,'/pml-testing.csv',sep=''),na.strings=c("NA","#DIV/0!",""))
```
### Data Cleaning
We first delect the columns with too many missing values. Here we set the threshold to be 80%. In other words, if a column contains more than 80% of missing values, this column is deleted.
```
N_row <- nrow(trData)
N_col <- ncol(trData)
threshold <- 0.8
col_na <- NULL
for (i in 1:N_col) {
	if (sum(is.na(trData[,i]))>(N_row*threshold)){
		col_na <- append(col_na,i)
	}
}
if (length(col_na)>0) {
	trData <- trData[,-col_na]
	tsData <- tsData[,-col_na]
}
```
After the column deletion, the number of columns is reduced from 159 to 59. Also, we need to remove the 1st, 3rd, 4th, 5th, and 6th columns, which are irrelevant to classe. 
```
trData <- trData[,-c(1,3,4,5,6)]
tsData <- tsData[,-c(1,3,4,5,6)]
```
Now, delete the rows with missing data from the training data:
```
row_na <- NULL
for (i in N_row) {
	if (sum(is.na(trData[i,]))>0){
		row_na <- append(row_na,i)
	}
}
if (length(row_na>0)) {
	trData <- trData[-row_na,]
}
```
### Data Partition
```
set.seed(1989)
intrain <- createDataPartition (trData$classe,p=0.7,list=FALSE)
data_train <- trData[intrain,]
data_test <- trData[-intrain,]
```
### Cross Validation
In this project we applied the 5-fold cross validation.
```
ctrl <- trainControl(method='cv',num = 5)
```
## Prediction Models
In this project we apply three different methods to do the predition. They are: classification tree, random forest, and support vector machine (SVM). 
### Classification Tree
```
mod_rpart <- train(classe ~ ., data=data_train, method="rpart", trControl=ctrl)
```
The results are as follows:
```
## CART 
##
## 13737 samples
##    58 predictor
##     5 classes: 'A', 'B', 'C', 'D', 'E' 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 10990, 10988, 10989, 10991, 10990 
## Resampling results across tuning parameters:
## 
##   cp          Accuracy   Kappa     
##   0.03529651  0.6264026  0.52894558
##   0.03617808  0.5068104  0.34807944
##   0.11341674  0.3310836  0.07136299

## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was cp = 0.03529651. 
```
The tree
```
fancyRpartPlot(mod_rpart$finalModel)
```
![The tree generated by 'rpart'](/rpart.jpeg)
Evaluation
```
pred_rpart <- predict(mod_rpart,data_test)
conf_rpart <- confusionMatrix(data_test$classe,pred_rpart)
```
```
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1517   27  127    0    3
##          B  483  369  287    0    0
##          C  496   30  500    0    0
##          D  433  171  360    0    0
##          E  150  153  274    0  505
## 
## Overall Statistics
##                                           
##                Accuracy : 0.4912          
##                  95% CI : (0.4784, 0.5041)
##     No Information Rate : 0.5232          
##     P-Value [Acc > NIR] : 1               
##                                           
##                   Kappa : 0.3348          
## Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.4927   0.4920  0.32300       NA  0.99409
## Specificity            0.9440   0.8500  0.87872   0.8362  0.89269
## Pos Pred Value         0.9062   0.3240  0.48733       NA  0.46673
## Neg Pred Value         0.6291   0.9197  0.78432       NA  0.99938
## Prevalence             0.5232   0.1274  0.26304   0.0000  0.08632
## Detection Rate         0.2578   0.0627  0.08496   0.0000  0.08581
## Detection Prevalence   0.2845   0.1935  0.17434   0.1638  0.18386
## Balanced Accuracy      0.7184   0.6710  0.60086       NA  0.94339
```
From the confusion matrix, the accuracy is 0.4912, which is not good enough.
### Random Forest
Now we apply random forest.
```
set.seed(2017)
mod_rf <- train(classe~., data=data_train, method='rf',trControl=ctrl)
```
Use confusion matrix to evalute the model
```
pred_rf <- predict(mod_rf,data_test)
conf_rf <- confusionMatrix(data_test$classe,pred_rpart)
```
The results are:
```
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1674    0    0    0    0
##          B    6 1133    0    0    0
##          C    0    2 1024    0    0
##          D    0    0    6  956    2
##          E    0    0    0    5 1077
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9964          
##                  95% CI : (0.9946, 0.9978)
##     No Information Rate : 0.2855          
##     P-Value [Acc > NIR] : < 2.2e-16       
##                                           
##                   Kappa : 0.9955          
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9964   0.9982   0.9942   0.9948   0.9981
## Specificity            1.0000   0.9987   0.9996   0.9984   0.9990
## Pos Pred Value         1.0000   0.9947   0.9981   0.9917   0.9954
## Neg Pred Value         0.9986   0.9996   0.9988   0.9990   0.9996
## Prevalence             0.2855   0.1929   0.1750   0.1633   0.1833
## Detection Rate         0.2845   0.1925   0.1740   0.1624   0.1830
## Detection Prevalence   0.2845   0.1935   0.1743   0.1638   0.1839
## Balanced Accuracy      0.9982   0.9985   0.9969   0.9966   0.9986
```
The accuracy is 0.9964.
### SVM
Now apply SVM
```
set.seed(15452)
mod_svm <- svm(classe~., data=data_train, trControl=ctrl)
```
Use confusion matrix to evalute the model
```
pred_svm <- predict(mod_svm,data_test)
conf_svm <- confusionMatrix(data_test$classe,pred_svm)
```
And the result is
```
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1651    5   15    0    3
##          B  104  999   29    2    5
##          C    3   44  970    8    1
##          D    2    0   93  868    1
##          E    0    8   14   18 1042
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9397          
##                  95% CI : (0.9333, 0.9456)
##     No Information Rate : 0.2991          
##     P-Value [Acc > NIR] : < 2.2e-16       
##                                           
##                   Kappa : 0.9236          
##  Mcnemar's Test P-Value : < 2.2e-16       
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9381   0.9460   0.8653   0.9688   0.9905
## Specificity            0.9944   0.9710   0.9882   0.9808   0.9917
## Pos Pred Value         0.9863   0.8771   0.9454   0.9004   0.9630
## Neg Pred Value         0.9741   0.9880   0.9689   0.9943   0.9979
## Prevalence             0.2991   0.1794   0.1905   0.1523   0.1788
## Detection Rate         0.2805   0.1698   0.1648   0.1475   0.1771
## Detection Prevalence   0.2845   0.1935   0.1743   0.1638   0.1839
## Balanced Accuracy      0.9662   0.9585   0.9268   0.9748   0.9911
```
The accuracy is 0.9397.
## Prediction 
Among the three algorithms applied, random forest has the highest accuracy. Therefore, we use random forest to do the prediction.
```
pred_test <- predict(mod_rf,tsData)
```
```
##  [1] B A B A A E D B A A B C B A E E A B B B
## Levels: A B C D E
```